---
title: 'Connectives and cognitive control: Data analysis'
author: "Elizabeth Swanson"
date: "2023-04-26"
output: html_document
---

# Set-up

Load required packages:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(eyetrackingR)
library(lme4)
library(readxl)
library(lmerTest)
source("helpers.R")
theme_set(theme_bw())
```

# Preparing data

## Eye-tracking data

Load eye-tracking data (make sure you unzip the .zip file if you haven't already):
```{r}
et_data = read.table('../data/conn_cog_control_timebin_1000sbefore.txt', sep = "\t", na.strings = ".", header = TRUE)
```

Prepare eye-tracking data:
```{r}
et_data$time_since_connective_onset = et_data$BIN_START_TIME - 1000
# change this if you generate timebin report starting at a point other than 1000s before connective onset

et_data$participant_number = et_data$RECORDING_SESSION_LABEL
```

Fix labeling of so and but conditions:
```{r}
et_data = et_data %>% mutate(condition = case_when(
  condition == "alors" ~ "so",
  condition == "mais" ~ "but"
),
condition_fr = case_when(
  condition == "so" ~ "alors",
  condition == "but" ~ "mais"
))

et_data$condition = relevel(factor(et_data$condition), ref = 'but')
```

Correct a few errors in coding explicit selection choices (all noted in comments):
```{r}
et_data$lex_related_image_selected[et_data$participant_number == 21032301 & et_data$TRIAL_LABEL == 'Trial: 9'] = 1
et_data$lex_related_image_selected[et_data$participant_number == 21032304 & et_data$TRIAL_LABEL == 'Trial: 22'] = 0
et_data$lex_related_image_selected[et_data$participant_number == 03042307 & et_data$TRIAL_LABEL == 'Trial: 17'] = 1
et_data$lex_related_image_selected[et_data$participant_number == 7042304 & et_data$TRIAL_LABEL == 'Trial: 23'] = 1
et_data$lex_related_image_selected[et_data$participant_number == 11042306 & et_data$TRIAL_LABEL == 'Trial: 13'] = 1
et_data$lex_related_image_selected[et_data$participant_number == 12042303 & et_data$TRIAL_LABEL == 'Trial: 19'] = 1
et_data$lex_related_image_selected[et_data$participant_number == 17032305 & et_data$TRIAL_LABEL == 'Trial: 16'] = 1
et_data$lex_related_image_selected[et_data$participant_number == 22032306 & et_data$TRIAL_LABEL == 'Trial: 1'] = 1
et_data$lex_related_image_selected[et_data$participant_number == 10042305 & et_data$TRIAL_LABEL == 'Trial: 1'] = 0
```

Make eye-tracking data:
```{r}
et_df = make_eyetrackingr_data(et_data, 
                       participant_column = 'RECORDING_SESSION_LABEL',
                       trial_column = 'trialnumber',
                       time_column = 'time_since_connective_onset',
                       aoi_columns = c('AVERAGE_IA_1_SAMPLE_COUNT_.', 'AVERAGE_IA_2_SAMPLE_COUNT_.'),
                       treat_non_aoi_looks_as_missing = TRUE,
                       trackloss_column = 'AVERAGE_OFF_SCREEN_SAMPLE_COUNT_.'
                       )
```

## Participant data

Load participant data:
```{r}
participant_df = read_excel('../data/participant-log-connectives-cog-control.xlsx')
participant_df = participant_df %>% type.convert()
```

Rename age groups:
```{r}
participant_df = participant_df %>% mutate(age_group = case_when(
  age_group == '4' ~ '4-year-olds',
  age_group == '5' ~ '5-year-olds',
  age_group == '6' ~ '6-year-olds',
  age_group == 'adult' ~ 'adults'
))
```

## Flanker data

Load Flanker data:
```{r}
flanker_files = list.files(path = '../data/flanker_data', full.names = TRUE)
flanker_df = plyr::ldply(flanker_files, read_csv)
flanker_df = flanker_df %>% type.convert()
flanker_df$participant_number_fl = flanker_df$subject
```


## Merging data

Merge eye-tracking data and participant data:
```{r}
et_df = left_join(et_df, participant_df, by = "participant_number")
et_df$lex_related_image_selected = as.numeric(et_df$lex_related_image_selected)
```

Merge Flanker data and participant data:
```{r}
flanker_df = left_join(flanker_df, participant_df, by = "participant_number_fl")
```

Exclude children who did not complete novel word learning task:
```{r}
flanker_df = flanker_df %>% filter(!is.na(participant_number))
length(unique(flanker_df$participant_number_fl))
```

## Exclusions

Exclude participants who were distracted, bilingual, etc:
```{r}
et_df = et_df %>% filter(exclude == "no")
```

Exclude participants who didn't complete more than half the trials:
```{r}
et_df = et_df %>% group_by(participant_number) %>% 
  mutate(total_trials_completed = max(TRIAL_INDEX)) %>%
  filter(total_trials_completed >= 12)
```

Check the number of participants in each age group:
```{r}
et_df %>% group_by(participant_number) %>% filter(row_number() == 1) %>%
  group_by(age_group) %>% summarise(n = n())
```

Exclude these participants from Flanker data too:
```{r}
flanker_df = flanker_df %>% filter(participant_number %in% et_df$participant_number)
```

Write Flanker data to a separate file since we will calculate Flanker costs separately:
```{r}
write.csv(flanker_df, '../data/flanker_df.csv')
```

Flanker cost calculations are done in a separate script so load that data:
```{r}
full_flanker_df = read.csv('../data/full_flanker_df.csv')
```

# Data visualization

## Time course

Pull out test trials:
```{r}
test_df = et_df %>% filter(practicestatus == "test")
```

Make time sequence data:
```{r}
df_timecourse <- make_time_sequence_data(test_df, time_bin_size = 1, 
                                         predictor_columns = c("condition", "age_group", "child_adult_group"),
                                         aois = c("AVERAGE_IA_1_SAMPLE_COUNT_."),
                                         summarize_by = "participant_number")
```

Make time course graph by age group:
```{r}
plot(df_timecourse, predictor_column = "condition") + theme_bw() +  theme(text = element_text(size = 10)) +  
  geom_hline(yintercept=0.5, colour="black",size=I(0.5),show.legend = FALSE)+
  geom_vline(xintercept=0, colour="black",size=I(0.5),show.legend = FALSE) +
  ylim(0,1) +
  xlim(-1000, 4000) +
  facet_wrap(~age_group) +
  annotate("text", x=-150, y=.9, label="connective \nonset", size = 2) +
  xlab("Time since connective onset (ms)") +
  ylab("Proportion of looks to lexically related image") +
  ggtitle("Proportion of looks to lexically related image by condition")

ggsave('timecourse_age_group.pdf', path = '../graphs', height = 6, width = 8)
```

Make time course graph for children vs. adults:
```{r}
plot(df_timecourse, predictor_column = "condition") + theme_bw() +  
  theme(text = element_text(size = 10)) +  
  geom_hline(yintercept=0.5, colour="black",size=I(0.5),show.legend = FALSE)+
  geom_vline(xintercept=0, colour="black",size=I(0.5),show.legend = FALSE) +
  ylim(0,1) +
  xlim(-500, 4000) +
  facet_wrap(~child_adult_group) +
  annotate("text", x=-150, y=.9, label="connective \nonset", size = 2) +
  xlab("Time since connective onset (ms)") +
  ylab("Proportion of looks to lexically related image") +
  ggtitle("Proportion of looks to lexically related image by condition")

ggsave('timecourse_child_adult.pdf', path = '../graphs', height = 6, width = 8)
```

## Cluster analysis

Separate time course data into children vs. adults:
```{r}
df_timecourse_children = df_timecourse %>% filter(child_adult_group == 'child')
df_timecourse_adult = df_timecourse %>% filter(child_adult_group == 'adult')
```


Make time cluster data for children:
```{r}
df_timeclust_children = make_time_cluster_data(df_timecourse_children,
                                      test= "t.test",
                                      predictor_column = "condition",
                                      aoi = "AVERAGE_IA_1_SAMPLE_COUNT_.",
                                      threshold = 1.5,
                                      formula = ArcSin ~ condition)
```

Plot time cluster data for children:
```{r}
plot(df_timeclust_children, predictor_column = "condition") + theme_bw() +  
  theme(text = element_text(size = 10)) + 
  geom_hline(yintercept=0.5, colour="black",size=I(0.5),show.legend = FALSE)+
  geom_vline(xintercept=0, colour="black",size=I(1.5),show.legend = FALSE)
```

Make time cluster data for adults:
```{r}
df_timeclust_adult = make_time_cluster_data(df_timecourse_adult,
                                      test= "t.test",
                                      predictor_column = "condition",
                                      aoi = "AVERAGE_IA_1_SAMPLE_COUNT_.",
                                      threshold = 1.5,
                                      formula = ArcSin ~ condition)
```

Plot time cluster data for adults:
```{r}
plot(df_timeclust_adult, predictor_column = "condition") + theme_bw() +  
  theme(text = element_text(size = 10)) + 
  geom_hline(yintercept=0.5, colour="black",size=I(0.5),show.legend = FALSE)+
  geom_vline(xintercept=0, colour="black",size=I(1.5),show.legend = FALSE)
```


## Explicit selection data

Create dataframe with one row per trial per participant:
```{r}
test_df_trial = test_df %>% group_by(participant_number, TRIAL_LABEL) %>%
  filter(row_number() == 1) %>%
  group_by(participant_number, condition) %>%
  mutate(total_trials_cond = n(),
         partic_prop_lex_related_image_selected = mean(na.omit(lex_related_image_selected)))
```

Create data frame with one row per participant per condition:
```{r}
test_df_participant = test_df_trial %>% group_by(participant_number, condition) %>%
  filter(row_number() == 1)
```

Summarize number of trials on each condition for which participants selected the lexically related image:
```{r}
selection_summ = test_df_participant %>%
  group_by(condition, age_group) %>%
  summarise(n = n(), 
            mean_prop_lex_related_image_selected = mean(partic_prop_lex_related_image_selected),
            CI.low = ci.low(partic_prop_lex_related_image_selected),
            CI.high = ci.high(partic_prop_lex_related_image_selected)) %>%
  mutate(YMin = mean_prop_lex_related_image_selected - CI.low, 
         YMax = mean_prop_lex_related_image_selected + CI.high)
```

Graph proportion of trials on each condition for which participants selected the lexically related image:
```{r}
ggplot(selection_summ) +
  theme_bw() +
  aes(x = condition, y = mean_prop_lex_related_image_selected, fill = condition) +
  facet_wrap(~age_group) +
  geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) + 
  geom_jitter(data = test_df_participant, aes(x = condition, y = partic_prop_lex_related_image_selected), 
              shape = 21, size = 1, width = 0.2, height = 0, stroke = 0.4, alpha = 0.3) +
  geom_errorbar(aes(ymin = YMin, ymax = YMax), width = .2, position = position_dodge(.9)) +
  scale_fill_discrete(name = "Condition") +
  scale_y_continuous(limits = c(0, 1.06), oob = scales::squish) +
  ggtitle("Proportion of trials with lexically related image selected") +
  xlab("Condition") +
  ylab("Proportion of trials with lexically related image selected")

ggsave('selection_age_group_bar.pdf', path = '../graphs', height = 4, width = 6)
```

Graph proportion of trials on each condition for which participants selected the lexically related image:
```{r}
ggplot(selection_summ) +
  theme_bw() +
  aes(x = age_group, y = mean_prop_lex_related_image_selected, group = condition, color = condition) +
  geom_line() + 
  geom_point() +
  ylim(0,1.05) +
  geom_hline(yintercept=0.5, colour="black",linetype = 3, size=I(1),show.legend = FALSE)+
  geom_errorbar(aes(ymin = YMin, ymax = YMax), width = .2) +
  scale_color_discrete(name = "Condition") +
  ggtitle("Proportion of trials with lexically related image selected by age group") +
  xlab("Age group") +
  ylab("Proportion of trials with lexically related image selected")

ggsave('selection_age_group_line.pdf', path = '../graphs', height = 4, width = 6)
```

# Data analysis

## Pointing performance

Create a column for accuracy on each pointing trial:
```{r}
test_df_trial = test_df_trial %>% 
  mutate(correct_point = case_when(
  condition == 'so' & lex_related_image_selected == 1 ~ TRUE,
  condition == 'but' & lex_related_image_selected == 0 ~ TRUE,
  TRUE ~ FALSE
  ))
```

Run a mixed model to see if condition predicts pointing to lexically related image:
```{r}
pointing_lm = lmer(lex_related_image_selected ~ condition +
                     (1|participant_number) + (1|novelword), 
                   data = test_df_trial)
summary(pointing_lm)
```

Run a mixed model to see if condition and age group predict pointing to lexically related image:
```{r}
pointing_age_lm = lmer(lex_related_image_selected ~ condition + age_group +
                     (1|participant_number) + (1|novelword), 
                   data = test_df_trial)
summary(pointing_age_lm)
```

## Proportion of looks

Pull out looking data from after connective onset:
```{r}
window_test_df = subset_by_window(test_df, 
                                  window_start_time = 0,
                                  window_end_time = 4000)
```

Remove trackloss-ridden trials:
```{r}
window_test_df_clean <- clean_by_trackloss(data = window_test_df, trial_prop_thresh = .25)
```


Pull out trials with looks to the lexically or non-lexically related image:
```{r}
#test_df_prop_looks = test_df %>% filter(AVERAGE_IA_1_SAMPLE_COUNT != 0 | 
                                          #AVERAGE_IA_2_SAMPLE_COUNT != 0)
```

Calculate each participant's proportion of looks to the lexically related image over the trial:
```{r}
window_test_df_partic = make_time_window_data(window_test_df, 
                                              aois = 'AVERAGE_IA_1_SAMPLE_COUNT_.',
                                              predictor_columns = c("condition", "age_group", "child_adult_group"), 
                                              summarize_by = "participant_number")
```

Plot raw prop looking data by age group:
```{r}
plot(window_test_df_partic, predictor_columns = c("condition"), dv = "Prop") + theme_bw() +
  facet_wrap(~age_group) +
  ylim(0,1) +
  xlab("Condition") +
  ylab("Proportion of looks to lexically related image") +
  ggtitle("Proportion of looks to lexically related image by condition")

ggsave('timecluster_age_group.pdf', path = '../graphs', height = 6, width = 8)
```

Plot raw prop looking data for children vs. adults:
```{r}
plot(window_test_df_partic, predictor_columns = c("condition"), dv = "Prop") + theme_bw() +
  facet_wrap(~child_adult_group) +
  ylim(0,1) +
  xlab("Condition") +
  ylab("Proportion of looks to lexically related image") +
  ggtitle("Proportion of looks to lexically related image by condition")

ggsave('timecluster_child_adult_group.pdf', path = '../graphs', height = 6, width = 8)
```

Pull out just ArcSin-transformed prop of looks for adults and children:
```{r}
prop_looks_partic_child = window_test_df_partic %>% select(participant_number, condition, age_group, child_adult_group, ArcSin) %>% filter(child_adult_group == 'child') %>%
  spread(key = 'condition', value = 'ArcSin') %>%
  rename(arcsin_prop_looks_but = but, arcsin_prop_looks_so = so)

prop_looks_partic_adult = window_test_df_partic %>% select(participant_number, condition, age_group, child_adult_group, ArcSin) %>% filter(child_adult_group == 'adult') %>%
  spread(key = 'condition', value = 'ArcSin') %>%
  rename(arcsin_prop_looks_but = but, arcsin_prop_looks_so = so)
```

T test to see if there is a significant difference in proportion of looks to lexically related image by condition for children:
```{r}
t.test(prop_looks_partic_child$arcsin_prop_looks_so, prop_looks_partic_child$arcsin_prop_looks_but, paired = TRUE)
t.test(prop_looks_partic_adult$arcsin_prop_looks_so, prop_looks_partic_adult$arcsin_prop_looks_but, paired = TRUE)
```

Pull out just raw prop of looks for adults and children:
```{r}
#raw_prop_looks_partic_child = window_test_df_partic %>% select(participant_number, condition, age_group, child_adult_group, Prop) %>% filter(child_adult_group == 'child') %>%
  #spread(key = 'condition', value = 'Prop') %>%
  #rename(raw_prop_looks_but = but, raw_prop_looks_so = so)

#raw_prop_looks_partic_adult = window_test_df_partic %>% select(participant_number, condition, age_group, child_adult_group, Prop) %>% filter(child_adult_group == 'adult') %>%
 # spread(key = 'condition', value = 'Prop') %>%
  #rename(raw_prop_looks_but = but, raw_prop_looks_so = so)
```

## Relationship of Flanker performance and pointing performance

Read in Flanker and pointing data:
```{r}
test_df_participant = read.csv('test_df_participant.csv', stringsAsFactors = TRUE)
full_flanker_df = read.csv('full_flanker_data.csv', stringsAsFactors = TRUE)
```


Create a column for accuracy on pointing trials:
```{r}
participant_pointing_df = test_df_participant %>% 
  mutate(partic_prop_correct_points = case_when(
  condition == 'so' ~ partic_prop_lex_related_image_selected,
  condition == 'but' ~ (1 - partic_prop_lex_related_image_selected)))
```


We will only be analyzing children, as adults did not complete the Flanker task:
```{r}
participant_pointing_df = participant_pointing_df %>% filter(child_adult_group == 'child')
```

Calculate participants' proportion of correct points on so and but trials:
```{r}
participant_pointing_df = participant_pointing_df %>% 
  group_by(participant_number, condition) %>%
  summarise(partic_prop_correct_points = partic_prop_correct_points,
            participant_number_fl = participant_number_fl,
            age_group = age_group,
            age_months = age_months)
```

Reshape to create dataframe with one row per participant:
```{r}
participant_pointing_df = participant_pointing_df %>% 
  spread(key = 'condition', value = 'partic_prop_correct_points') %>%
  rename(prop_correct_points_but = but, prop_correct_points_so = so)
```

Merge with Flanker data:
```{r}
participant_pointing_df = full_join(participant_pointing_df, full_flanker_df)
```

Change age to z-score:
```{r}
participant_pointing_df$mean_age_months = mean(participant_pointing_df$age_months)
participant_pointing_df$sd_age_months = sd(participant_pointing_df$age_months)
participant_pointing_df = participant_pointing_df %>% 
  mutate(age_months_z_score = (age_months - mean_age_months)/sd_age_months)
```

Change proportion correct points for but to z-scores:
```{r}
participant_pointing_df$mean_prop_correct_points_but = mean(participant_pointing_df$prop_correct_points_but)
participant_pointing_df$sd_prop_correct_points_but = sd(participant_pointing_df$prop_correct_points_but)
participant_pointing_df = participant_pointing_df %>% 
  mutate(prop_correct_points_but_z_score = ((prop_correct_points_but - mean_prop_correct_points_but)/sd_prop_correct_points_but))
```

Change proportion correct points for so to z-scores:
```{r}
participant_pointing_df$mean_prop_correct_points_so = mean(participant_pointing_df$prop_correct_points_so)
participant_pointing_df$sd_prop_correct_points_so = sd(participant_pointing_df$prop_correct_points_so)
participant_pointing_df = participant_pointing_df %>% 
  mutate(prop_correct_points_so_z_score = ((prop_correct_points_so - mean_prop_correct_points_so)/sd_prop_correct_points_so))
```


Run a regression to test whether Flanker performance predicts performance on but trials:
```{r}
fl_pointing_lm = lm(prop_correct_points_but_z_score ~ composite_congruency_effect + composite_switch_effect + nogo_cost_z_score + age_months_z_score + prop_correct_points_so_z_score, data = participant_pointing_df)
summary(fl_pointing_lm)
```

Try without combining RT and acc z-scores:
```{r}
fl_pointing_separate_lm = lm(prop_correct_points_but_z_score ~ flanker_congruency_z_score_rt + flanker_congruency_z_score_errors + flanker_switch_z_score_rt + flanker_switch_z_score_errors +  nogo_cost_z_score + age_months_z_score + prop_correct_points_so_z_score, data = participant_pointing_df)
summary(fl_pointing_separate_lm)
```


## Relationship of Flanker performance and looking to lexically related image

Merge Flanker data and proportion of looks data:
```{r}
prop_looks_partic_fl = left_join(prop_looks_partic_child, participant_df)
prop_looks_partic_fl = full_join(prop_looks_partic_fl, full_flanker_df)
```

Calculate z-score for proportion of looks to correct image on so trials:
```{r}
prop_looks_partic_fl$mean_arcsin_prop_looks_but = mean(prop_looks_partic_fl$arcsin_prop_looks_but)
prop_looks_partic_fl$sd_arcsin_prop_looks_but = sd(prop_looks_partic_fl$arcsin_prop_looks_but)
prop_looks_partic_fl = prop_looks_partic_fl %>% 
  mutate(arcsin_prop_looks_but_z_score = ((arcsin_prop_looks_but - mean_arcsin_prop_looks_but)/sd_arcsin_prop_looks_but))
```

Calculate z-score for proportion of looks to correct image on but trials:
```{r}
prop_looks_partic_fl$mean_arcsin_prop_looks_so = mean(prop_looks_partic_fl$arcsin_prop_looks_so)
prop_looks_partic_fl$sd_arcsin_prop_looks_so = sd(prop_looks_partic_fl$arcsin_prop_looks_so)
prop_looks_partic_fl = prop_looks_partic_fl %>% 
  mutate(arcsin_prop_looks_so_z_score = ((arcsin_prop_looks_so - mean_arcsin_prop_looks_so)/sd_arcsin_prop_looks_so))
```

Change age to z-score:
```{r}
prop_looks_partic_fl$mean_age_months = mean(prop_looks_partic_fl$age_months)
prop_looks_partic_fl$sd_age_months = sd(prop_looks_partic_fl$age_months)
prop_looks_partic_fl = prop_looks_partic_fl %>% 
  mutate(age_months_z_score = (age_months - mean_age_months)/sd_age_months)
```

Run a regression to test whether Flanker performance predicts looking performance on but trials:
```{r}
fl_looking_lm = lm(arcsin_prop_looks_but_z_score ~ composite_congruency_effect + composite_switch_effect + nogo_cost_z_score + age_months_z_score + arcsin_prop_looks_so_z_score, data = prop_looks_partic_fl)
summary(fl_looking_lm)
```

Try without combining RT and acc z-scores:
```{r}
fl_looking_separate_lm = lm(arcsin_prop_looks_but_z_score ~ flanker_congruency_z_score_rt + flanker_congruency_z_score_errors + flanker_switch_z_score_rt + flanker_switch_z_score_errors +  nogo_cost_z_score + age_months_z_score + arcsin_prop_looks_so_z_score, data = prop_looks_partic_fl)
summary(fl_looking_separate_lm)
```


Try predicting correct points on so trials:
```{r}
fl_pointing_so_lm = lm(prop_correct_points_so ~ composite_congruency_effect + composite_switch_effect +  nogo_cost_z_score + age_group, data = participant_pointing_df)
summary(fl_pointing_so_lm)
```

Try without combining RT and acc z-scores:
```{r}
fl_pointing_so_sep_lm = lm(prop_correct_points_so ~ flanker_congruency_z_score_rt + flanker_congruency_z_score_acc + flanker_switch_z_score_rt + flanker_switch_z_score_acc +  nogo_cost_z_score + age_group, data = participant_pointing_df)
summary(fl_pointing_so_sep_lm)
```


Putting but prop errors in z-score:
```{r}
participant_pointing_df = participant_pointing_df %>% mutate(
  prop_but_errors = 1 - prop_correct_points_but
)
participant_pointing_df$overall_mean_prop_but_errors = mean(na.omit(participant_pointing_df$prop_but_errors))
participant_pointing_df$overall_sd_prop_but_errors = sd(na.omit(participant_pointing_df$prop_but_errors))
participant_pointing_df = participant_pointing_df %>% mutate(
  prop_but_errors_z_score = ((prop_but_errors - overall_mean_prop_but_errors)/overall_sd_prop_but_errors),
)
```

Run a regression to test whether Flanker performance predicts but errors:
```{r}
fl_pointing_but_error_lm = lm(prop_but_errors_z_score ~ composite_congruency_effect + composite_switch_effect + nogo_cost_z_score + age_group + prop_correct_points_so, data = participant_pointing_df)
summary(fl_pointing_but_error_lm)
```

Try without combining RT and acc z-scores:
```{r}
fl_pointing_but_error_sep_lm = lm(prop_but_errors_z_score ~ flanker_congruency_z_score_rt + flanker_congruency_z_score_acc + flanker_switch_z_score_rt + flanker_switch_z_score_acc +  nogo_cost_z_score + age_group, data = participant_pointing_df)
summary(fl_pointing_but_error_sep_lm)
```














SCRATCH:

Summarize number of trials on each condition for which participants selected the lexically related image (OLD VERSION WITH ALL TRIALS TOGETHER)
```{r}
selection_summ = test_df %>% group_by(participant_number, TRIAL_LABEL) %>%
  filter(row_number() == 1) %>%
  group_by(condition, age_group) %>%
  mutate(total_trials_cond = n()) %>%
  group_by(condition, lex_related_image_selected, age_group) %>%
  summarise(n = n(), total_trials_cond = unique(total_trials_cond), 
            prop = unique(n()/total_trials_cond),
            CI.low = prop - 1.96*sqrt(prop*(1-prop)/total_trials_cond),
            CI.high = prop + 1.96*sqrt(prop*(1-prop)/total_trials_cond)) %>%
  filter(lex_related_image_selected == 1)
```



